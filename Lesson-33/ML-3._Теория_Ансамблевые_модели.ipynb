{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# АНСАМБЛЕВЫЕ МОДЕЛИ\n",
    "\n",
    "Или просто ансамбли (ensembles) — это метод машинного обучения, где несколько простых моделей (часто называемых «слабыми учениками») обучаются для решения одной и той же задачи и объединяются для получения лучших результатов.\n",
    "\n",
    "Необходимость использования ансамблей может возникнуть тогда, когда вы уже нашли хорошую модель и никак больше не можете повысить её качество. В этом случае можно перейти к более продвинутому методу: использовать не одну модель (пусть и очень хорошую), а ансамбли моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Говоря простыми словами, ансамбли — это объединение простых моделей в одного гиганта. Но объединять модели можно как угодно: например, взять тысячу разных логистических регрессий, а затем на их предсказаниях построить дерево решений, линейную регрессию или вообще нейронную сеть. А можно обучить сотню деревьев решений — построить целый лес, а для предсказания взять среднее. Вариаций объединения может быть сколько угодно.\n",
    "\n",
    "Существует три проверенных способа построения ансамблей:\n",
    "\n",
    "* Бэггинг — параллельно обучаем множество одинаковых моделей, а для предсказания берём среднее по предсказаниям каждой из моделей.\n",
    "\n",
    "* Бустинг — последовательно обучаем множество одинаковых моделей, где каждая новая модель концентрируется на тех примерах, где предыдущая допустила ошибку.\n",
    "\n",
    "* Стекинг — параллельно обучаем множество разных моделей, отправляем их результаты в финальную модель, и уже она принимает решение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# БЭГГИНГ (bagging)\n",
    "\n",
    "Это алгоритм построения ансамбля путём параллельного обучения множества независимых друг от друга моделей.\n",
    "\n",
    "Bootstrap-выборка — это метод повторной выборки с возвращением. Используется для статистической оценки параметров модели и проверки её устойчивости.\n",
    "\n",
    "Примечание: Такие бутстрэп-выборки часто используются для оценки различных статистических показателей (например, разброса или доверительного интервала). Если вычислять статистические оценки на нескольких независимых выборках, то мы можем оценить их разброс. Поиск большого количества независимых выборок сложен в силу того, что для этого требуется слишком много данных. Поэтому мы используем бутстрэп, чтобы создать несколько выборок.\n",
    "\n",
    "<img src='Images/ml_13.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание: В случае классификации «усреднение» означает мажоритарное голосование (принцип большинства голосов). То есть объект относится к тому классу, за который проголосовало большинство алгоритмов.\n",
    "\n",
    "Важно отметить, что в бэггинге в голосовании принимает участие **модель одного вида**. Эта модель называется базовой моделью (base model). Нельзя обучить на половине сгенерированных наборов данных логистические регрессии, а на второй половине — деревья решений.\n",
    "\n",
    "Примечание: Главное преимущество бэггинга — это уменьшение разброса базовой модели за счёт параллельного построения множества моделей на различных обучающих наборах данных. Тем самым уменьшается риск переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# СЛУЧАЙНЫЙ ЛЕС\n",
    "\n",
    "Случайный лес (Random Forest) — это самая распространённая реализация бэггинга, основанная на использовании в качестве базовой модели дерева решений.\n",
    "\n",
    "Помимо бутстрэпа, случайный лес использует метод случайных подпространств. Суть этого метода заключается в том, что каждая модель обучается не на всех признаках, а только на части из них. Такой подход позволяет уменьшить коррелированность между ответами деревьев и сделать их независимыми друг от друга.\n",
    "\n",
    "Метод случайных подпространств — это техника ансамблевого обучения, похожая на бэггинг, но с акцентом на отбор признаков, а не объектов.\n",
    "\n",
    "Суть метода:\n",
    "\n",
    "* Для каждой модели из ансамбля выбирается случайное подмножество признаков (подпространство признаков), на которых она будет обучаться.\n",
    "\n",
    "* Полный набор объектов остается неизменным (в отличие от бэггинга, где создаются бутстрэп-выборки из объектов).\n",
    "\n",
    "Ниже приведена схема работы описанного алгоритма для решения задачи классификации. Для простоты лес состоит из четырёх деревьев (K=4).\n",
    "\n",
    "<img src='Images/ml_14.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что деревья, из которых состоит лес, могут быть различной глубины и структуры в зависимости от того, насколько просто была разделима поданная выборка.\n",
    "\n",
    "Теперь, когда поступят новые данные, нам останется только подать их на вход каждого из деревьев, получить предсказания, а затем усреднить их путём мажоритарного голосования и получить ответ."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
